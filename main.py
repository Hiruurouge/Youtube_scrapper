# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VGEt6Td8PMfWYJfUYXHcJDD1xZP-VMuz
"""

import requests
from bs4 import BeautifulSoup
import json
import re
import unicodedata
import sys
import getopt
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time

N=5
def get_url(inputfile):
    f = open(inputfile);
    data = json.load(f)
    url_table = []
    for i in data['videos_id']:
        url_table.append('https://youtu.be/'+i)
    return (url_table)


def scrap(url):
    s=Service(ChromeDriverManager().install())
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    driver = webdriver.Chrome(service=s, chrome_options=options)
    driver.get(url)
    time.sleep(2)
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")
    body = soup.find_all("body")[0]
    scripts = body.find_all("script")
    result = json.loads(scripts[0].string[30:-1])

    Video_details = result['videoDetails']

    title = soup.find("meta", itemprop="name")['content']
    description = soup.find("meta", itemprop="description")['content']
    views = Video_details['viewCount']
    author = Video_details['author']
    id = Video_details['videoId']

    description = unicodedata.normalize(
        'NFKD', Video_details['shortDescription']).encode('ascii', 'ignore')
    description = str(description.decode())
    description = description.replace('\n', '')

    data = re.search(r"var ytInitialData = ({.*?});", soup.prettify()).group(1)
    data = json.loads(data)
    videoPrimaryInfoRenderer = data['contents']['twoColumnWatchNextResults'][
        'results']['results']['contents'][0]['videoPrimaryInfoRenderer']
    likes = videoPrimaryInfoRenderer['videoActions']['menuRenderer']['topLevelButtons'][0][
        'segmentedLikeDislikeButtonRenderer']['likeButton']['toggleButtonRenderer']['defaultText']['simpleText']
    comm = []
    element = driver.find_element(By.XPATH,"//*[@id=\"comments\"]")
    driver.execute_script("arguments[0].scrollIntoView();", element)
    dsoup = BeautifulSoup(driver.page_source, 'html.parser')
    commentsList = dsoup.find_all("ytd-comment-thread-renderer", {"class": "style-scope ytd-item-section-renderer"}, limit = N)
    while commentsList == []:
        time.sleep(1)
        dsoup = BeautifulSoup(driver.page_source, 'html.parser')
        commentsList = dsoup.find_all("ytd-comment-thread-renderer", {"class": "style-scope ytd-item-section-renderer"}, limit = N)
    for comment in commentsList:
        comm.append(comment.find("yt-formatted-string", {"id": "content-text"}).text)
    final = data = {"title": title,
                   "views": views,
                   "likes": likes,
                   "description": description,
                   "author": author,
                   "id": id,
                    "comm":comm}
    return final


def generate_json(url_table,outputfile):
    f = open("output.json", "w")
    for i in range(len(url_table)):
        if i == 0:
            f.write('[')
        json.dump(scrap(url_table[i]), f)
        if i != len(url_table)-1:
            f.write(',')
        if i == len(url_table)-1:
            f.write(']')
    f.close()
    return 0


def main(argv):
    inputfile = ''
    outputfile = ''
    try:
        opts, args = getopt.getopt(argv,"hi:o:",["inputfile=","outputfile="])
    except getopt.GetoptError:
      print('test.py -i <inputfile> -o <outputfile>')
      sys.exit(2)
    for opt, arg in opts:
        if opt == '-h':
            print('test.py -i <inputfile> -o <outputfile>')
            sys.exit()
        elif opt in ("-i", "--inputfile"):
            inputfile = arg
        elif opt in ("-o", "--outputfile"):
            outputfile = arg    
    url_table=get_url(inputfile)
    generate_json(url_table,outputfile)

if __name__ == "__main__":
    main(sys.argv[1:])